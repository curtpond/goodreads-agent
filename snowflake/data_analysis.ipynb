{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goodreads Data Analysis and Cleaning for Snowflake\n",
    "\n",
    "This notebook analyzes and prepares the Goodreads dataset for Snowflake ingestion, with special focus on text reviews for AI processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Import our data preparation module\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from snowflake.data_preparation import load_and_clean_data, calculate_quality_score\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Examine Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the raw data\n",
    "raw_df = pd.read_csv('../data/books.csv')\n",
    "\n",
    "print(\"Dataset Shape:\", raw_df.shape)\n",
    "print(\"\\nColumns:\", raw_df.columns.tolist())\n",
    "print(\"\\nData Types:\")\n",
    "raw_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment\n",
    "\n",
    "Let's examine the quality of our data before cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_data_quality(df):\n",
    "    quality_report = pd.DataFrame({\n",
    "        'missing_values': df.isnull().sum(),\n",
    "        'missing_percentage': (df.isnull().sum() / len(df) * 100).round(2),\n",
    "        'unique_values': df.nunique(),\n",
    "        'sample_values': df.apply(lambda x: list(x.dropna().sample(min(3, len(x.dropna()))).values))\n",
    "    })\n",
    "    \n",
    "    return quality_report\n",
    "\n",
    "quality_report = analyze_data_quality(raw_df)\n",
    "quality_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Reviews Analysis\n",
    "\n",
    "Since we're planning to use text reviews for AI processing, let's analyze the review statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze review counts\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=raw_df, x='text_reviews_count', bins=50)\n",
    "plt.title('Distribution of Text Review Counts')\n",
    "plt.xlabel('Number of Text Reviews')\n",
    "plt.ylabel('Count of Books')\n",
    "plt.yscale('log')  # Log scale for better visualization\n",
    "plt.show()\n",
    "\n",
    "# Print review statistics\n",
    "print(\"\\nText Reviews Statistics:\")\n",
    "print(raw_df['text_reviews_count'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clean and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clean the data using our preparation module\n",
    "clean_df = load_and_clean_data('../data/books.csv')\n",
    "\n",
    "# Compare before and after cleaning\n",
    "print(\"Data Quality Scores:\")\n",
    "print(clean_df['data_quality_score'].describe())\n",
    "\n",
    "# Plot quality score distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=clean_df, x='data_quality_score', bins=30)\n",
    "plt.title('Distribution of Data Quality Scores')\n",
    "plt.xlabel('Quality Score')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare Data Model for Snowflake\n",
    "\n",
    "We'll create a normalized data model with separate tables for books, authors, and publishers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_snowflake_tables(df):\n",
    "    # Create authors dimension table\n",
    "    authors = (df['authors'].str.split('/')\n",
    "              .explode()\n",
    "              .str.strip()\n",
    "              .dropna()\n",
    "              .unique())\n",
    "    authors_df = pd.DataFrame({\n",
    "        'author_id': range(1, len(authors) + 1),\n",
    "        'author_name': authors\n",
    "    })\n",
    "    \n",
    "    # Create publishers dimension table\n",
    "    publishers = df['publisher'].dropna().unique()\n",
    "    publishers_df = pd.DataFrame({\n",
    "        'publisher_id': range(1, len(publishers) + 1),\n",
    "        'publisher_name': publishers\n",
    "    })\n",
    "    \n",
    "    return authors_df, publishers_df\n",
    "\n",
    "# Create dimension tables\n",
    "authors_df, publishers_df = create_snowflake_tables(clean_df)\n",
    "\n",
    "print(\"Number of unique authors:\", len(authors_df))\n",
    "print(\"Number of unique publishers:\", len(publishers_df))\n",
    "\n",
    "# Display sample of dimension tables\n",
    "print(\"\\nSample Authors:\")\n",
    "print(authors_df.head())\n",
    "print(\"\\nSample Publishers:\")\n",
    "print(publishers_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Data for Snowflake\n",
    "\n",
    "Prepare and save the cleaned data in a format suitable for Snowflake ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create output directory\n",
    "output_dir = '../snowflake/prepared_data'\n",
    "import os\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the prepared files\n",
    "clean_df.to_csv(f'{output_dir}/books_for_snowflake.csv', index=False)\n",
    "authors_df.to_csv(f'{output_dir}/authors_for_snowflake.csv', index=False)\n",
    "publishers_df.to_csv(f'{output_dir}/publishers_for_snowflake.csv', index=False)\n",
    "\n",
    "print(\"Files exported successfully to:\", output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
